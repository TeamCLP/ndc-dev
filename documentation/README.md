# SCRIBE AI â€” Documentation Pipeline de DonnÃ©es

> **De la collecte des donnÃ©es Ã  l'entraÃ®nement du modÃ¨le**

ğŸ“ Repository : [github.com/TeamCLP/ndc-dev](https://github.com/TeamCLP/ndc-dev)

---

## Table des matiÃ¨res

1. [Vue d'ensemble](#1-vue-densemble)
2. [SchÃ©ma du Pipeline](#2-schÃ©ma-du-pipeline)
3. [Inventaire des Programmes](#3-inventaire-des-programmes)
4. [Ã‰tape 1 â€” Collecte](#4-Ã©tape-1--collecte-des-donnÃ©es)
5. [Ã‰tape 2 â€” Classification](#5-Ã©tape-2--classification)
6. [Ã‰tape 3 â€” Nettoyage](#6-Ã©tape-3--nettoyage--dÃ©duplication)
7. [Ã‰tape 4 â€” Appariement](#7-Ã©tape-4--appariement-edb-ndc)
8. [Ã‰tape 5 â€” Conversion](#8-Ã©tape-5--conversion-markdown)
9. [Ã‰tape 6 â€” PrÃ©paration Dataset](#9-Ã©tape-6--prÃ©paration-du-dataset)
10. [Ã‰tape 7 â€” EntraÃ®nement](#10-Ã©tape-7--entraÃ®nement-fine-tuning)
11. [Comparaison train.py vs train2.py](#11-comparaison-trainpy-vs-train2py)
12. [Structure du Repository](#12-structure-du-repository)

---

## 1. Vue d'ensemble

**SCRIBE AI** automatise la gÃ©nÃ©ration de Notes de Cadrage (NDC) Ã  partir d'Expressions de Besoins (EDB) en utilisant un modÃ¨le **Mistral 7B fine-tunÃ©** sur des donnÃ©es historiques internes du domaine bancaire.

### Deux approches d'entraÃ®nement

| Version | Script | Description | Cas d'usage |
|---------|--------|-------------|-------------|
| **V1** | `train.py` | GÃ©nÃ©ration par **champs individuels** avec balises `<START>/<END>` | Interface interactive |
| **V2** | `train2.py` | GÃ©nÃ©ration de **documents complets** (EDB â†’ Devis Markdown) | GÃ©nÃ©ration batch |

---

## 2. SchÃ©ma du Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           PIPELINE SCRIBE AI                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  1.COLLECTE â”‚â”€â”€â”€â–¶â”‚2.CLASSIF.   â”‚â”€â”€â”€â–¶â”‚ 3.NETTOYAGE â”‚â”€â”€â”€â–¶â”‚4.APPARIEMENTâ”‚
  â”‚  SQL+DL     â”‚    â”‚  Scoring    â”‚    â”‚  DÃ©dupe     â”‚    â”‚  EDB-NDC    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                                        â”‚
         â–¼                                                        â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ 7.TRAINING  â”‚â—€â”€â”€â”€â”‚ 6.DATASET   â”‚â—€â”€â”€â”€â”‚5.CONVERSION â”‚â—€â”€â”€â”€â”‚   Couples   â”‚
  â”‚ train.py    â”‚    â”‚  JSONL      â”‚    â”‚  Markdown   â”‚    â”‚   EDB-NDC   â”‚
  â”‚ train2.py   â”‚    â”‚             â”‚    â”‚             â”‚    â”‚             â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   MODÃˆLE    â”‚
  â”‚  FINE-TUNÃ‰  â”‚
  â”‚   + LoRA    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Inventaire des Programmes

| # | Ã‰tape | Programme | Statut | Description |
|---|-------|-----------|--------|-------------|
| 1 | Collecte | `extraction_sql.sql` | ğŸ”´ Ã€ dÃ©poser | RequÃªte SQL pour identifier les documents |
| 2 | Collecte | `download_files.py` | ğŸ”´ Ã€ dÃ©poser | TÃ©lÃ©chargement depuis l'outil interne |
| 3 | Classification | `classify_documents.py` | ğŸ”´ Ã€ dÃ©poser | Scoring automatique EDB vs NDC vs AUTRE |
| 4 | Nettoyage | `pipeline_nettoyage_complet.py` | ğŸŸ¢ PrÃ©sent | DÃ©duplication + renommage RITM |
| 5 | Appariement | `couples_edb_ndc.py` | ğŸŸ¢ PrÃ©sent | Matching EDB-NDC par RITM |
| 6 | Conversion | `extract.py` | ğŸŸ¢ PrÃ©sent | Extraction contenu Word |
| 7 | Conversion | `convert_devis_et_edb_docx_to_markdown.py` | ğŸŸ¢ PrÃ©sent | Conversion DOCX â†’ Markdown |
| 8 | PrÃ©paration | `build_dataset_jsonl.py` | ğŸŸ¢ PrÃ©sent | Construction dataset JSONL |
| 9 | EntraÃ®nement | `train.py` | ğŸŸ¢ PrÃ©sent | Fine-tuning V1 â€” Champs |
| 10 | EntraÃ®nement | `train2.py` | ğŸŸ¢ PrÃ©sent | Fine-tuning V2 â€” Documents |

---

## 4. Ã‰tape 1 â€” Collecte des DonnÃ©es

> â³ **Scripts Ã  dÃ©poser**

### 1.1 extraction_sql.sql

**RÃ´le :** RequÃªte SQL pour identifier les documents EDB et NDC dans l'outil interne.

**Sortie :** Liste des fichiers Ã  tÃ©lÃ©charger avec mÃ©tadonnÃ©es (rÃ©fÃ©rence RITM, type, chemin)

### 1.2 download_files.py

**RÃ´le :** TÃ©lÃ©chargement des fichiers identifiÃ©s.

**Sortie :** Dossier `Data/` contenant les fichiers bruts (PDF + Word)

---

## 5. Ã‰tape 2 â€” Classification

> â³ **Script Ã  dÃ©poser**

### classify_documents.py

**RÃ´le :** Classification automatique des documents en EDB, NDC ou AUTRE via scoring.

**EntrÃ©e :** Dossier `Data/`

**Sortie :** `analyse_documents.xlsx`

**Colonnes de sortie :**
- `Filename_Original` â€” Nom du fichier
- `Reference` â€” RÃ©fÃ©rence RITM extraite
- `RITM_Parent` â€” RITM parent si applicable
- `Type_Document` â€” EDB | NDC | AUTRE
- `Score_EDB` / `Score_NDC` â€” Scores de classification

---

## 6. Ã‰tape 3 â€” Nettoyage & DÃ©duplication

### pipeline_nettoyage_complet.py ğŸŸ¢

**EntrÃ©es :**
- `analyse_documents.xlsx`
- Dossier `Data/`

**Sorties :**
- Dossier `clean2/`
- `analyse_documents_enrichi.xlsx`

**RÃ¨gles de traitement :**

| RÃ¨gle | Action |
|-------|--------|
| Type = `AUTRE` | â†’ SupprimÃ© |
| PDF existe ET Word avec mÃªme nom | â†’ PDF supprimÃ©, Word conservÃ© |
| Fichier conservÃ© | â†’ RenommÃ© `{RITM}-{TYPE}-{nom}.ext` |
| Fichier renommÃ© | â†’ CopiÃ© vers `clean2/` |

**Colonnes ajoutÃ©es :**
- `Statut_Fichier` : CONSERVE | SUPPRIME
- `Nom_Fichier_Clean2` : Nouveau nom

**ExÃ©cution :**
```bash
python pipeline_nettoyage_complet.py
```

---

## 7. Ã‰tape 4 â€” Appariement EDB-NDC

### couples_edb_ndc.py ğŸŸ¢

**EntrÃ©es :**
- `analyse_documents_enrichi.xlsx`
- Dossier `clean2/`

**Sortie :** `couverture_EDB_NDC_par_RITM.xlsx`

**Logique :**
1. Extraction des RITM uniques
2. Pour chaque RITM : comptage EDB et NDC
3. Identification des couples complets (â‰¥1 EDB + â‰¥1 NDC)
4. DÃ©tection prÃ©sence PDF

**Colonnes du rapport :**

| Colonne | Description |
|---------|-------------|
| `RITM` | RÃ©fÃ©rence unique |
| `Nb_EDB` | Nombre d'EDB |
| `Nb_NDC` | Nombre de NDC |
| `Couple_EDB_NDC` | OUI si couple complet |
| `Presence_PDF_EDB_NDC` | OUI si PDF prÃ©sent |
| `Documents_EDB` | Liste fichiers EDB |
| `Documents_NDC` | Liste fichiers NDC |

**ExÃ©cution :**
```bash
python couples_edb_ndc.py
```

---

## 8. Ã‰tape 5 â€” Conversion Markdown

### extract.py ğŸŸ¢

**RÃ´le :** Extraction de contenu textuel depuis documents Word.

### convert_devis_et_edb_docx_to_markdown.py ğŸŸ¢

**EntrÃ©e :** Fichiers DOCX des couples EDB-NDC

**Sortie :** Fichiers `.md`

**Outil :** Docling (IBM)

---

## 9. Ã‰tape 6 â€” PrÃ©paration du Dataset

### build_dataset_jsonl.py ğŸŸ¢

**EntrÃ©e :** Fichiers Markdown

**Sorties :**
- `dataset/train_dataset.jsonl`
- `dataset/val_dataset.jsonl`

**Format JSONL â€” Mistral Instruct :**

```json
{
  "messages": [
    {
      "role": "user",
      "content": "[INST] <TASK>contexte_proj</TASK>\n<CONTEXT>\nclient: Banque ABC\n</CONTEXT> [/INST]"
    },
    {
      "role": "assistant",
      "content": "<START>Le projet s'inscrit dans le cadre...<END>"
    }
  ]
}
```

---

## 10. Ã‰tape 7 â€” EntraÃ®nement (Fine-tuning)

### train.py â€” V1 Champs individuels ğŸŸ¢

**Cas d'usage :** GÃ©nÃ©ration de champs individuels avec balises `<START>/<END>`

**Configuration :**

| ParamÃ¨tre | Valeur |
|-----------|--------|
| ModÃ¨le | `mistralai/Mistral-7B-Instruct-v0.3` |
| Output dir | `/home/quentin/mistral-banking` |
| Max prompt | 1 536 tokens |
| Max response | 768 tokens |
| Max total | 2 304 tokens |
| LoRA r / alpha | 128 / 256 |
| Batch size | 8 |
| Gradient accum | 4 |
| Learning rate | 3e-5 |
| Epochs | 2 |
| Precision | bfloat16 |

**Commandes :**
```bash
python train.py                              # From scratch
python train.py --resume                     # Reprendre dernier checkpoint
python train.py --resume-from /path/to/ckpt  # Checkpoint spÃ©cifique
```

---

### train2.py â€” V2 Documents complets ğŸŸ¢

**Cas d'usage :** GÃ©nÃ©ration de documents Markdown complets (EDB â†’ Devis)

**Configuration :**

| ParamÃ¨tre | Valeur |
|-----------|--------|
| ModÃ¨le | `mistralai/Mistral-7B-Instruct-v0.3` |
| Output dir | `/home/quentin/mistral-devis` |
| Max prompt | **6 144 tokens** |
| Max response | **8 192 tokens** |
| Max total | **14 336 tokens** |
| LoRA r / alpha | 128 / 256 |
| Batch size | **2** |
| Gradient accum | **16** |
| Learning rate | **2e-5** |
| Epochs | **3** |
| Precision | bfloat16 |

**Commandes :**
```bash
python train2.py                             # From scratch
python train2.py --resume                    # Reprendre
python train2.py --output-dir /path/to/out   # Dossier personnalisÃ©
python train2.py --max-prompt-length 4096    # Longueurs personnalisÃ©es
```

---

### Monitoring TensorBoard

```bash
# V1
tensorboard --logdir=/home/quentin/runs/mistral-banking

# V2
tensorboard --logdir=/home/quentin/runs/mistral-devis
```

**MÃ©triques :**
- `train/loss` â€” Loss d'entraÃ®nement
- `eval/loss` â€” Loss de validation
- `val_gen/tag_rate` â€” Taux balises correctes (V1)
- `val_gen/avg_generation_time` â€” Temps gÃ©nÃ©ration
- `val_gen/avg_tokens_generated` â€” Tokens gÃ©nÃ©rÃ©s (V2)

---

## 11. Comparaison train.py vs train2.py

| Aspect | train.py (V1) | train2.py (V2) |
|--------|---------------|----------------|
| **Objectif** | Champs individuels | Documents complets |
| **Format entrÃ©e** | `<TASK>...<CONTEXT>` | EDB complÃ¨te (MD) |
| **Format sortie** | `<START>...<END>` | Devis complet (MD) |
| **Max prompt** | 1 536 tokens | 6 144 tokens |
| **Max response** | 768 tokens | 8 192 tokens |
| **Batch size** | 8 | 2 |
| **Gradient accum** | 4 | 16 |
| **Learning rate** | 3e-5 | 2e-5 |
| **Epochs** | 2 | 3 |
| **Validation** | Tags START/END | AperÃ§u devis |
| **Cas d'usage** | Interface interactive | GÃ©nÃ©ration batch |

---

## 12. Structure du Repository

```
ndc-dev/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ install.sh
â”œâ”€â”€ run_train.sh
â”‚
â”œâ”€â”€ â”€â”€â”€ PRÃ‰PARATION â”€â”€â”€
â”œâ”€â”€ pipeline_nettoyage_complet.py
â”œâ”€â”€ couples_edb_ndc.py
â”œâ”€â”€ extract.py
â”œâ”€â”€ convert_devis_et_edb_docx_to_markdown.py
â”œâ”€â”€ build_dataset_jsonl.py
â”‚
â”œâ”€â”€ â”€â”€â”€ ENTRAÃNEMENT â”€â”€â”€
â”œâ”€â”€ train.py                    # V1 - Champs
â”œâ”€â”€ train2.py                   # V2 - Documents
â”‚
â””â”€â”€ dataset/
    â”œâ”€â”€ train_dataset.jsonl
    â””â”€â”€ val_dataset.jsonl
```

### DÃ©pendances

```
torch==2.9.1
transformers==4.57.3
peft==0.18.1
datasets==4.4.2
accelerate==1.12.0
pandas
openpyxl
docling
```

### PrÃ©requis matÃ©riels

| Ressource | Minimum | RecommandÃ© |
|-----------|---------|------------|
| GPU VRAM | 24 Go (V1) | 80 Go (H100) |
| CUDA | 12.0+ | 12.8+ |
| Python | 3.10+ | 3.12 |

---

## TODO â€” Scripts Ã  dÃ©poser

- [ ] Script d'extraction SQL
- [ ] Script de tÃ©lÃ©chargement
- [ ] Script de classification/scoring
- [x] pipeline_nettoyage_complet.py
- [x] couples_edb_ndc.py
- [x] extract.py
- [x] convert_devis_et_edb_docx_to_markdown.py
- [x] build_dataset_jsonl.py
- [x] train.py
- [x] train2.py

---

*SCRIBE AI â€” Documentation Pipeline de DonnÃ©es*
*DerniÃ¨re mise Ã  jour : Janvier 2025*
